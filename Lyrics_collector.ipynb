{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for fetching html from Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_link_artist(artist):\n",
    "    '''\n",
    "    Fetches html link of the artist and saves the html in the folder.\n",
    "    The input has to be given as a string.\n",
    "    \n",
    "    '''\n",
    "    # Contrsuction of the whole url\n",
    "    \n",
    "    url_artist = f\"https://www.lyrics.com/artist/{artist}\"\n",
    "    resp_artist =  requests.get(url_artist)\n",
    "    time.sleep(random.random()/10+.01)\n",
    "    \n",
    "    # Write as a html file in the local folder\n",
    "    with open(f'./{artist}.html', 'w') as file:\n",
    "        file.write(resp_artist.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function for list of artist's lyrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_artist_link_lyrics(artist):\n",
    "    '''\n",
    "    Fetches list of links of songs of the artist in www.lyrics.com and returns a list containing\n",
    "    link of the lyrics and song names. The input has to be given as a string.\n",
    "    \n",
    "    '''\n",
    "    html_link_artist(artist) \n",
    "    # Reading the html file\n",
    "    HtmlFile_artist = open(f\"{artist}.html\", 'r', encoding='utf-8')\n",
    "    source_code_artist = HtmlFile_artist.read()\n",
    "    \n",
    "    # Use BeautySoup to find the lyrics links\n",
    "    # Create a BeautifulSoup object\n",
    "    \n",
    "    soup_artist = BeautifulSoup(source_code_artist)\n",
    "    song_links_artist = soup_artist.find_all('td', class_ = \"tal qx\")\n",
    "    return song_links_artist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_lyrics_artist(artist):\n",
    "    '''\n",
    "    Create a DataFrame of links of artist song lyrics.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    links_artist = []\n",
    "    for link_tag in list_artist_link_lyrics(artist):\n",
    "        link = link_tag.find('a').get('href')\n",
    "        link_text = link_tag.get_text()\n",
    "       # print(link, link_text)\n",
    "        links_artist.append((link, link_text))\n",
    "        \n",
    "    df_artist = pd.DataFrame(links_artist, columns=[  'song_link', 'song'])   \n",
    "    df_artist.drop_duplicates(inplace=True, subset=['song'], ignore_index=True)\n",
    "    return df_artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function for Lyrics collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyrics_artist(artist):\n",
    "    '''\n",
    "    Create a DataFrame of lyrics of artist songs.\n",
    "    '''\n",
    "    lyrics_artist = []\n",
    "    df = link_lyrics_artist(artist)\n",
    "    for link in tqdm(df['song_link']):\n",
    "        link_url = f\" https://www.lyrics.com{link}\"\n",
    "        resp_lyrics = requests.get(link_url)\n",
    "        time.sleep(random.random()/10+.01)\n",
    "        soup_lyrics = BeautifulSoup(resp_lyrics.text)\n",
    "        lyrics_text = soup_lyrics.find('pre', id ='lyric-body-text').get_text()\n",
    "        #print(lyrics_text, song_name)\n",
    "        lyrics_artist.append(lyrics_text)\n",
    "        \n",
    "    # Add the artist name and remove duplications with lyrics\n",
    "    df['lyrics']= lyrics_artist\n",
    "    df['artist_name']= f'{artist}'\n",
    "    df = df.drop_duplicates(subset=['lyrics'])\n",
    "\n",
    "    \n",
    "    return df\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load songs for The-Beatles, Pink-Floyd, Justin-Bieber, and Taylor-Swift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_link</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/lyric/35984628/The+Beatles/Blackbird</td>\n",
       "      <td>Blackbird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/lyric/36392416/The+Beatles/My+Bonnie</td>\n",
       "      <td>My Bonnie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/lyric/36255422/The+Beatles/Let+It+Be</td>\n",
       "      <td>Let It Be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/lyric/36255456/The+Beatles/Maggie+Mae</td>\n",
       "      <td>Maggie Mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/lyric/36255433/The+Beatles/Old+Brown+Shoe</td>\n",
       "      <td>Old Brown Shoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>/lyric/2541468/The+Beatles/Tomorrow+Never+Know...</td>\n",
       "      <td>Tomorrow Never Knows [Mark I - Unknown Take]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>/lyric/2541470/The+Beatles/Strawberry+Fields+F...</td>\n",
       "      <td>Strawberry Fields Forever [Take 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>/lyric/2541471/The+Beatles/Strawberry+Fields+F...</td>\n",
       "      <td>Strawberry Fields Forever [Take 5, 6, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>/lyric/2541475/The+Beatles/All+You+Need+Is+Lov...</td>\n",
       "      <td>All You Need Is Love [Take 58 - Live Televisio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>/lyric/2541476/The+Beatles/I+Am+the+Walrus+%5B...</td>\n",
       "      <td>I Am the Walrus [Take 9]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1356 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              song_link  \\\n",
       "0                 /lyric/35984628/The+Beatles/Blackbird   \n",
       "1                 /lyric/36392416/The+Beatles/My+Bonnie   \n",
       "2                 /lyric/36255422/The+Beatles/Let+It+Be   \n",
       "3                /lyric/36255456/The+Beatles/Maggie+Mae   \n",
       "4            /lyric/36255433/The+Beatles/Old+Brown+Shoe   \n",
       "...                                                 ...   \n",
       "1351  /lyric/2541468/The+Beatles/Tomorrow+Never+Know...   \n",
       "1352  /lyric/2541470/The+Beatles/Strawberry+Fields+F...   \n",
       "1353  /lyric/2541471/The+Beatles/Strawberry+Fields+F...   \n",
       "1354  /lyric/2541475/The+Beatles/All+You+Need+Is+Lov...   \n",
       "1355  /lyric/2541476/The+Beatles/I+Am+the+Walrus+%5B...   \n",
       "\n",
       "                                                   song  \n",
       "0                                             Blackbird  \n",
       "1                                             My Bonnie  \n",
       "2                                             Let It Be  \n",
       "3                                            Maggie Mae  \n",
       "4                                        Old Brown Shoe  \n",
       "...                                                 ...  \n",
       "1351       Tomorrow Never Knows [Mark I - Unknown Take]  \n",
       "1352           Strawberry Fields Forever [Take 2, 3, 4]  \n",
       "1353           Strawberry Fields Forever [Take 5, 6, 7]  \n",
       "1354  All You Need Is Love [Take 58 - Live Televisio...  \n",
       "1355                           I Am the Walrus [Take 9]  \n",
       "\n",
       "[1356 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_lyrics_artist('The-Beatles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9715c8b6f5ea4fbfa75a64b4e605cbc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1356.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_Beatles= lyrics_artist('The-Beatles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: Lyrics_Beatles.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the data for all as a csv file\n",
    "\n",
    "filename = 'Lyrics_Beatles.csv'\n",
    "\n",
    "df_Beatles.to_csv(filename,index=False)\n",
    "\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764cff381e2d4398b452e5053f9d9713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=399.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_Floyd = lyrics_artist('Pink-Floyd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: Lyrics_Floyd.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the data for all as a csv file\n",
    "\n",
    "filename = 'Lyrics_Floyd.csv'\n",
    "\n",
    "df_Floyd.to_csv(filename,index=False)\n",
    "\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef4b09a9f314fe68e9edd08b1396f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=266.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_Bieber = lyrics_artist('Justin-Bieber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: Lyrics_Bieber.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the data for all as a csv file\n",
    "\n",
    "filename = 'Lyrics_Bieber.csv'\n",
    "\n",
    "df_Bieber.to_csv(filename,index=False)\n",
    "\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf728741564e4ce195891c2083754728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=267.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_Swift = lyrics_artist('Taylor-Swift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: Lyrics_Swift.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the data for all as a csv file\n",
    "\n",
    "filename = 'Lyrics_Swift.csv'\n",
    "\n",
    "df_Swift.to_csv(filename,index=False)\n",
    "\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist = pd.concat([df_Beatles,df_Floyd, df_Bieber, df_Swift], ignore_index=True)\n",
    "#df_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: Lyrics_Artist.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the data for all as a csv file\n",
    "\n",
    "filename = 'Lyrics_Artist.csv'\n",
    "\n",
    "df_artist.to_csv(filename,index=False)\n",
    "\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One can use Spacy verb, adverb, noun, and stop word Parts of Speech (POS) tokens and pushes them into a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_spacy_data(dataset, feature_column):\n",
    "    '''\n",
    "    Grabs the verb, adverb, noun, and stop word Parts of Speech (POS) \n",
    "    tokens and pushes them into a new dataset. returns an \n",
    "    enriched dataset'''\n",
    "    verbs = []\n",
    "    nouns = []\n",
    "    adverbs = []\n",
    "    corpus = []\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "    ##\n",
    "    for i in range (0, len(dataset)):\n",
    "        print(\"Extracting verbs and topics from record {} of {}\".format(i+1, len(dataset)), end = \"\\r\")\n",
    "        song = dataset.iloc[i][feature_column]\n",
    "        doc = nlp(song)\n",
    "        spacy_dataframe = pd.DataFrame()\n",
    "        for token in doc:\n",
    "            if token.lemma_ == \"-PRON-\":\n",
    "                    lemma = token.text\n",
    "            else:\n",
    "                lemma = token.lemma_\n",
    "            row = {\n",
    "                \"Word\": token.text,\n",
    "                \"Lemma\": lemma,\n",
    "                \"PoS\": token.pos_,\n",
    "                \"Stop Word\": token.is_stop\n",
    "            }\n",
    "            spacy_dataframe = spacy_dataframe.append(row, ignore_index = True)\n",
    "        verbs.append(\" \".join(spacy_dataframe[\"Lemma\"][spacy_dataframe[\"PoS\"] == \"VERB\"].values))\n",
    "        nouns.append(\" \".join(spacy_dataframe[\"Lemma\"][spacy_dataframe[\"PoS\"] == \"NOUN\"].values))\n",
    "        adverbs.append(\" \".join(spacy_dataframe[\"Lemma\"][spacy_dataframe[\"PoS\"] == \"ADV\"].values))\n",
    "        corpus_clean = \" \".join(spacy_dataframe[\"Lemma\"][spacy_dataframe[\"Stop Word\"] == False].values)\n",
    "        corpus_clean = re.sub(r'[^A-Za-z0-9]+', ' ', corpus_clean)   \n",
    "        corpus.append(corpus_clean)\n",
    "    dataset['Verbs'] = verbs\n",
    "    dataset['Nouns'] = nouns\n",
    "    dataset['Adverbs'] = adverbs\n",
    "    dataset['Corpus'] = corpus\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting verbs and topics from record 996 of 996\r"
     ]
    }
   ],
   "source": [
    "prepped_training_data = add_spacy_data(df_artist, 'lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(996, 8)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepped_training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: Lyrics_Artist_spacy.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the data for all as a csv file\n",
    "\n",
    "filename = 'Lyrics_Artist_spacy.csv'\n",
    "\n",
    "prepped_training_data.to_csv(filename,index=False)\n",
    "\n",
    "print('Saved file: ' + filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
